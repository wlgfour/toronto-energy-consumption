---
title: "exploratory"
author: "William Gerecke"
date: "1/27/2022"
abstract: "This is my abstract.^[footnote]"
bibliography: bibliography.bib
output:
  bookdown::pdf_document2: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r, include=FALSE}
library(dplyr)
library(tidyverse)
library(opendatatoronto)
library(patchwork)
library(knitr)
library(reshape2)
library(janitor)
library(kableExtra)
```

```{r, include=FALSE}
load('inputs/data/cleaned/raw_geocoded.RData')
load('inputs/data/cleaned/raw.RData')
load('inputs/data/cleaned/cleaned.RData')
load(file='inputs/data/cleaned/ward_tbl.RData')

cleaned_geocoded <- cleaned_geocoded |>
  transform(ghg_emissions_kg = as.numeric(ghg_emissions_kg))
```

\newpage
# Intro

abbreviations:
- greenhouse gas (GHG)

TODO:
- data cleaning: don't hard code row counts
- check for past/present tense


# Data

## Software

This project uses the statistical programming language R [@citeR] to generate graphics and process data. The data is managed using `tidyverse` and processing is done using `dplyr` verbs [@tidy; @dplyr]. For geometry-specific processing, the `sf` package is used [@sf]. The data is downloaded from the Open Data Toronto Portal using the `opendatatoronto` package [@odt]. The `tidygeocoder` package is used to geocode addresses present in the downloaded data set [@tgeo].


## Source

Regarding this project there are two data sets of interest, both of which come from the Open Data Toronto Portal. The first is the Annual Energy Consumption data set which contains columns for the energy consumption of individual buildings in Toronto that are required by Ontario Regulation 397/11, the Green Energy Act (2009), to report their GHG emissions. Specifically, this data set contains annual `xlsx` spreadsheets from 2011-2018 that have columns with the building: name; address; floor area; mega liters of water or sewage treated; amount of energy purchased in the form of electricity and natural gas; and GHG emissions. The distribution by year of these features can be seen in Figure \@ref(fig:feature-plot). The features are plotted on a logarithmic scale because these features vary most significantly in their order of magnitude.

```{r feature-plot, echo=FALSE, warning=FALSE, out.width='75%', fig.align='center', fig.width=8, fig.height=6, fig.cap='Reports for GHG emissions, electricity consumption, and floor area by year on a logarithmic scale.'}
ghg <- cleaned_geocoded |>
  ggplot(mapping = aes(x = year, y = ghg_emissions_kg, group=year)) +
  geom_boxplot() +
  geom_jitter(alpha=0.05, width=0.2, height=0) +
  theme_classic() +
  labs(
    x = 'Year',
    y = 'GHg emissions (kg)'
  ) +
  scale_y_continuous(trans='log', labels=function(x) sprintf("%.1e", x)) +
  theme(axis.text.y = element_text(angle = 60, vjust = 0.5, hjust=0.5))

ele <- cleaned_geocoded |>
  ggplot(mapping = aes(x = year, y = electricity_wh, group=year)) +
  geom_boxplot() +
  geom_jitter(alpha=0.05, width=0.2, height=0) +
  theme_classic() +
  labs(
    x = 'Year',
    y = 'Electricity consumption (Wh)'
  ) +
  scale_y_continuous(trans='log', labels=function(x) sprintf("%.1e", x)) +
  theme(axis.text.y = element_text(angle = 60, vjust = 0.5, hjust=0.5))

flr <- cleaned_geocoded |>
  ggplot(mapping = aes(x = year, y = floor_area_sf, group=year)) +
  geom_boxplot() +
  geom_jitter(alpha=0.05, width=0.2, height=0) +
  theme_classic() +
  labs(
    x = 'Year',
    y = 'Floor area (sq. ft.)'
  ) +
  scale_y_continuous(trans='log', labels=function(x) sprintf("%.1e", x)) +
  theme(axis.text.y = element_text(angle = 60, vjust = 0.5, hjust=0.5))

(ele + flr) / ghg
```

The second data set is called City Wards and it contains a shape file (`.shp` extension) that describes the 25 municipal wards of Toronto. The data contains the name of each ward as well as its geospatial information that will be used to group building data by ward.

In order to identify which ward each building belongs to, the building coordinates are required (latitude and longitude), which are obtained by using the `tidygeocoder` package. The `tidygeocoder` package is free and open source, but geocoding API requests are limited to one request per second.


## Cleaning

The Annual Energy Consumption dataset is provided in the form of several `xlsx` spreadsheets with a preamble at the top and grouped cells that describe column labels. The top rows were truncated and columns were manually assigned the correct labels. Additionally, there was one file containing spreadsheets for the years 2011-2014 which had to be separated. There were several paired columns where one contained a number and the other contained a unit. These were appropriately converted to the same unit using standard unit conversions. Finally, some postal codes contained a space in the middle (e.g. `M4Y 0A9`) and some did not. For the purpose of geocoding, these had to be converted to the prior format.

In order to identify which wards each building belongs to, they were geocoded by address, postal code, city, and country. There were `r length(unique(raw_geocoded$address_snth))` unique addresses, `r sum(is.na(raw_geocoded$latitude))` of which could not be geocoded that could not be geocoded for various reasons, such as `'Various addresses'` in the address column. In order to reduce the strain on the Nomination API, only unique addresses were geocoded which reduced the number of necessary calls to the API by `r nrow(raw_geocoded) - length(unique(raw_geocoded$address_snth))`. The yearly reports and a summary of the geocoding process can be seen in Table \@ref(tab:yearly-reps).

```{r yearly-reps, echo=FALSE, fig.align='center'}
# fig.cap='Number of yearly reports collected with the number of un-geocoded addresses shown by year.'

rgeo <- raw_geocoded |>
  mutate(geocode_succ = if_else(!is.na(longitude), 'success', 'failure'))

#rgeo |>
#  ggplot(mapping = aes(x = year, fill=geocode_succ)) +
#  geom_bar() +
#  theme_minimal() +
#  labs(
#    x = 'Year reported',
#    y = 'Number of reports',
#    fill = 'Geocode status'
#  )

by_year = rgeo |>
  count(year, geocode_succ) |>
  dcast(geocode_succ ~ year, value.var=c('n')) |>
  adorn_totals(where=c('row', 'col'))

by_year |>
  kable(
    col.names = c(c("Geocode status"), colnames(by_year)[2:9], 'Total'),
    booktabs = TRUE, 
    linesep = '',
    format.args = list(big.mark = ","),
    caption = 'Number of successful and unsuccessful gecoded addresses for each year.'
  ) |>
  row_spec(2, hline_after=T) |>
  column_spec(10, border_left = TRUE, bold = TRUE)
```

Each building in the dataset was assigned a ward based on which ward's boundaries the geocoded point for that building intersected with. At the end of the cleaning process, excess columns were dropped, rows with invalid data were dropped, and the dataset was saved to the `inputs/data/cleaned` directory. The number of buildings that submitted reports in each ward is shown in Figure \@ref(fig:ward-reps).

```{r ward-reps, echo=FALSE, out.width='75%', fig.align='center', fig.width=8, fig.height=4, fig.cap='Number of reports each year for each ward.'}
ward_by_year <- cleaned_geocoded |>
  count(ward, year)
  
ward_by_year |>
  ggplot(mapping = aes(x = year, y = n, color=ward)) +
  geom_point() +
  geom_line(alpha=0.25, size=1.2) +
  theme_classic() +
  theme(legend.position = 'bottom', legend.text = element_text(size=8)) +
  labs(
    x = 'Year',
    y = 'Number of reports',
    color = 'Ward'
  )
```



# Results


# Discussion

- geocoding by postal code and not address
  - might assign to wrong ward
- dropped wrong values
- some buildings aren't required to report
  - some buildings chose to report and weren't required to
    - possibly skew results because people wouldn't want to report if they were bad




















